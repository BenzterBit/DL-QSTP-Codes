{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenzterBit/DL-QSTP-Codes/blob/master/YOLOv3%20Trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtPffI9k67C8",
        "colab_type": "code",
        "outputId": "cf787de4-a244-4343-e61e-4a6a76e9b76d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "source": [
        "#Getting configuration file for YOLO (Like downloading the pretrained network)\n",
        "%%shell\n",
        "mkdir cfg\n",
        "cd cfg\n",
        "wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
        "pip install --upgrade wandb\n",
        "# @hidden\n",
        "wandb login 0ec07493250352b2c3a0596b81e4e91d1a2b9c48"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-15 13:45:26--  https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8342 (8.1K) [text/plain]\n",
            "Saving to: ‘yolov3.cfg’\n",
            "\n",
            "\ryolov3.cfg            0%[                    ]       0  --.-KB/s               \ryolov3.cfg          100%[===================>]   8.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-07-15 13:45:26 (130 MB/s) - ‘yolov3.cfg’ saved [8342/8342]\n",
            "\n",
            "Requirement already up-to-date: wandb in /usr/local/lib/python3.6/dist-packages (0.8.5)\n",
            "Requirement already satisfied, skipping upgrade: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.0)\n",
            "Requirement already satisfied, skipping upgrade: backports.tempfile>=1.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.0)\n",
            "Requirement already satisfied, skipping upgrade: gql>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.1.0)\n",
            "Requirement already satisfied, skipping upgrade: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.1.11)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: watchdog>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (0.5.0)\n",
            "Requirement already satisfied, skipping upgrade: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: backports.weakref in /usr/local/lib/python3.6/dist-packages (from backports.tempfile>=1.0->wandb) (1.0.post1)\n",
            "Requirement already satisfied, skipping upgrade: promise>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from gql>=0.1.0->wandb) (2.2.1)\n",
            "Requirement already satisfied, skipping upgrade: graphql-core>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from gql>=0.1.0->wandb) (2.2)\n",
            "Requirement already satisfied, skipping upgrade: gitdb2>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2019.6.16)\n",
            "Requirement already satisfied, skipping upgrade: pathtools>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (0.1.2)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: argh>=0.24.1 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (0.26.2)\n",
            "Requirement already satisfied, skipping upgrade: rx>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from graphql-core>=0.5.0->gql>=0.1.0->wandb) (1.6.1)\n",
            "Requirement already satisfied, skipping upgrade: smmap2>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from gitdb2>=2.0.0->GitPython>=1.0.0->wandb) (2.0.5)\n",
            "Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[32mSuccessfully logged in to Weights & Biases!\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwuL-lpn7ieh",
        "colab_type": "code",
        "outputId": "95a9dcfa-f894-4bef-ab25-5ad762799eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from __future__ import division\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import os\n",
        "import wandb\n",
        "wandb.init(project=\"yolo\")\n",
        "%cd cfg"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/helloharshit68/yolo/runs/88p9mnsa\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
              "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/content/cfg/cfg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWY25hNp7MNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmptyLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EmptyLayer, self).__init__()\n",
        "        \n",
        "class DetectionLayer(nn.Module):\n",
        "    def __init__(self, anchors):\n",
        "        super(DetectionLayer, self).__init__()\n",
        "        self.anchors = anchors\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8ahakI59LOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_cfg(directory=\"/content/cfg\"):\n",
        "  direct=os.listdir(directory)\n",
        "  file = open(direct[1], 'r')\n",
        "  lines = file.read().split('\\n')                        # store the lines in a list\n",
        "  lines = [x for x in lines if len(x) > 0]               # get read of the empty lines \n",
        "  lines = [x for x in lines if x[0] != '#']              # get rid of comments\n",
        "  lines = [x.rstrip().lstrip() for x in lines]           # get rid of the extreme left and right spaces in the line\n",
        "  block = {}\n",
        "  blocks = []\n",
        "  for line in lines:\n",
        "      if line[0] == \"[\":               # This marks the start of a new block eg [convolutional]\n",
        "          if len(block) != 0:          # If block is not empty, implies it is storing values of previous block\n",
        "              blocks.append(block)     # add it the blocks list\n",
        "              block = {}               # re-init the block\n",
        "          block[\"type\"] = line[1:-1].rstrip()     # [convolutional] ,so the block[\"type\"] = made convolutional as '1' ignores '[' and :-1 ignores ']'\n",
        "      else:                                         # append value to block\n",
        "          key,value = line.split(\"=\")  # splitting = , LHS = key , RHS = value ,only if it isn't the start of the block.\n",
        "          block[key.rstrip()] = value.lstrip() # key is like convolutional , padding etc. removes the spaces between '=' and key and between '=' and value \n",
        "  blocks.append(block)                         # appending the last block\n",
        "  return blocks\n",
        "\n",
        "#so the flow works like first it checks whether the first letter is '[' if so goes inside the 'if' statement\n",
        "#then it checks if the length of block is zero , if its not it means it contains the values from the previous block and should be appended to the block.\n",
        "#else if the length of block is zero , then line would represent the following line \n",
        "#[convolutional]\n",
        "#else if the first letter isn't '[' then it goes in the else part, splits line in key vlaue pair and stores it inside block variable\n",
        "#as we reach the beginning of next block [convolutional]\n",
        "#len(block)!=0 and the previous block is appended and then re initialized.\n",
        "#at the end we do appending for the last block variable as it exits the 'for' loop\n",
        "#and then we return the list 'blocks'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEc7-cIljqgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_modules(blocks):# To create the CNN\n",
        "    net_info = blocks[0]     #Captures the information about the input and pre-processing , basically the [net] is initialized to it.   \n",
        "    module_list = nn.ModuleList() #like an iterable module( list of modules) we need it dude to the large size (58) of number of layers\n",
        "    prev_filters = 3 #coresponding to rgb channels, as a pre initialization for the first layer.\n",
        "    output_filters = []\n",
        "    for index, x in enumerate(blocks[1:]): # aside from the first block it captures the remaining blocks(58 in number) into module\n",
        "      module = nn.Sequential() \n",
        "      \n",
        "      \n",
        "      if x[\"type\"]==\"convolutional\" :\n",
        "        try:\n",
        "          batchnorm=int(x[\"batch_normalize\"] )# if there is a batch norm present in the module then assign to variable batchnorm\n",
        "          bias=False  # bias is +B part in calculation of NN , this gets canceled out in batch normalization so we do not require bias here\n",
        "        except:\n",
        "          batchnorm=0 #BN not present\n",
        "          bias=True\n",
        "        filters=int(x[\"filters\"])\n",
        "        kernel_size=int(x[\"size\"])\n",
        "        stride=int(x[\"stride\"])\n",
        "        padding=int(x[\"pad\"]) # padding here is a boolean , it just says if padding is present or not , it is our job to calculate it\n",
        "        if padding: # if present\n",
        "          pad=(kernel_size-1)//2    #// is for division with output as integer  (why same padding???)\n",
        "        else: \n",
        "          pad=0\n",
        "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
        "        conv=nn.Conv2d(prev_filters, filters, kernel_size, stride=stride, padding=pad, bias=bias)\n",
        "        module.add_module(\"conv_{0}\".format(index), conv) #add module {index}\n",
        "\n",
        "        if batchnorm:\n",
        "          #torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "          bn=nn.BatchNorm2d(filters)\n",
        "          module.add_module(\"batch_norm_{0}\".format(index), bn) #add module {index}\n",
        "        if x[\"activation\"]==\"leaky\":\n",
        "          leaky_relu=nn.LeakyReLU(0.1,inplace=True)\n",
        "          module.add_module(\"leaky_relu_{0}\".format(index), leaky_relu) #add module {index}\n",
        "          \n",
        "          \n",
        "      elif x[\"type\"] == \"upsample\":       # if beginning of block/type is [upsample]\n",
        "        stride = int(x[\"stride\"])\n",
        "        upsample = nn.Upsample(scale_factor = 2, mode = \"bilinear\") #We use Bilinear2dUpsampling\n",
        "        module.add_module(\"upsample_{}\".format(index), upsample)\n",
        "            \n",
        "\n",
        "      elif (x[\"type\"] == \"route\"):            #If it is a route layer or beginning of block/type is [route]\n",
        "          x[\"layers\"] = x[\"layers\"].split(',') # as layers can contain multiple values seperated by ','\n",
        "          #Start  of a route\n",
        "          start = int(x[\"layers\"][0])          #first value of 'layers' \n",
        "          #end, if there exists one.\n",
        "          try:#trying to access x[\"layers\"][1] is access allowed then assign it to variable 'end'\n",
        "              end = int(x[\"layers\"][1])\n",
        "          except:#if exception occurs and access is denied\n",
        "              end = 0\n",
        "          #Positive anotation\n",
        "          if start > 0: \n",
        "              start = start - index            #subtracting index if start is greater than 0. not applicable in this config\n",
        "          if end > 0:\n",
        "              end = end - index               #subtraction index if end is greater than 0. applicable is this config.\n",
        "          route = EmptyLayer()\n",
        "          module.add_module(\"route_{0}\".format(index), route) #add an emptylayer irrespective of the previous operations\n",
        "          if end < 0:              # if only one value in layers, then the output 'x' will be the feature map of i+start 'th layer\n",
        "              filters = output_filters[index + start] + output_filters[index + end]  #else if 2 values in layers, add 2 filters i+start and i+end \n",
        "          else:\n",
        "              filters= output_filters[index + start]\n",
        "#followubg is the code from the darknet(nn.Module)\n",
        "#thats why we make route 'empty' layer so that we can directly access it in darknet class' forward method.\n",
        "              '''\n",
        "elif module_type == \"route\":     #if module type is root\n",
        "  layers = modules[i][\"layers\"]  #access the \"layers\" of the i'th module\n",
        "  layers = [int(a) for a in layers] #converting layers to 'int'\n",
        "                \n",
        "if (layers[0]) > 0:               #equivalnet to start > 0\n",
        "  layers[0] = layers[0] - i\n",
        "                    \n",
        "if len(layers) == 1:\n",
        "  x = outputs[i + (layers[0])]   # if only one value in layers, then the output 'x' will be the feature map of i+layers[0] 'th layer\n",
        "                    \n",
        "\n",
        "else:\n",
        "  if (layers[1]) > 0:            #equivalent explaination to end>0\n",
        "    layers[1] = layers[1] - i\n",
        "                        \n",
        "  map1 = outputs[i + layers[0]]\n",
        "  map2 = outputs[i + layers[1]]                    \n",
        "                    \n",
        "  x = torch.cat((map1, map2), 1) #concat along the depth dimension \n",
        "outputs[i] = x                  #assign 'x' to this layer output.\n",
        "'''  \n",
        "\n",
        "              \n",
        "      elif x[\"type\"] == \"shortcut\":\n",
        "        shortcut = EmptyLayer()\n",
        "        module.add_module(\"shortcut_{}\".format(index), shortcut)\n",
        "        '''\n",
        "elif  module_type == \"shortcut\":\n",
        "  from_ = int(modules[i][\"from\"])\n",
        "  x = outputs[i-1] + outputs[i+from_]\n",
        "  outputs[i] = x \n",
        "  \n",
        "'''\n",
        "#Yolo is the detection layer\n",
        "      elif x[\"type\"] == \"yolo\":\n",
        "        mask = x[\"mask\"].split(\",\") \n",
        "        mask = [int(x) for x in mask]\n",
        "\n",
        "        anchors = x[\"anchors\"].split(\",\") #the spaces in between each pair won't matter inside the list.\n",
        "        anchors = [int(a) for a in anchors]\n",
        "        anchors = [(anchors[i], anchors[i+1]) for i in range(0, len(anchors),2)]\n",
        "        anchors = [anchors[i] for i in mask]\n",
        "\n",
        "        detection = DetectionLayer(anchors)\n",
        "        module.add_module(\"Detection_{}\".format(index), detection)\n",
        "        \n",
        "      module_list.append(module)\n",
        "      prev_filters = filters\n",
        "      output_filters.append(filters)\n",
        "    return (net_info, module_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY4s_bYmesK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gczHPz2_jpna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import cv2 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ5tW1dRjqHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_transform(prediction, inp_dim, anchors, num_classes, CUDA = True):\n",
        "  batch_size = prediction.size(0)\n",
        "  stride =  inp_dim // prediction.size(2)\n",
        "  grid_size = inp_dim // stride\n",
        "  bbox_attrs = 5 + num_classes\n",
        "  num_anchors = len(anchors)\n",
        "\n",
        "  prediction = prediction.view(batch_size, bbox_attrs*num_anchors, grid_size*grid_size)\n",
        "  prediction = prediction.transpose(1,2).contiguous()\n",
        "  prediction = prediction.view(batch_size, grid_size*grid_size*num_anchors, bbox_attrs)\n",
        "  \n",
        "  anchors = [(a[0]/stride, a[1]/stride) for a in anchors]\n",
        "  #Sigmoid the  centre_X, centre_Y. and object confidencce\n",
        "  prediction[:,:,0] = torch.sigmoid(prediction[:,:,0])\n",
        "  prediction[:,:,1] = torch.sigmoid(prediction[:,:,1])\n",
        "  prediction[:,:,4] = torch.sigmoid(prediction[:,:,4])\n",
        "  \n",
        "  #Add the center offsets\n",
        "  grid = np.arange(grid_size)\n",
        "  a,b = np.meshgrid(grid, grid)\n",
        "\n",
        "  x_offset = torch.FloatTensor(a).view(-1,1)\n",
        "  y_offset = torch.FloatTensor(b).view(-1,1)\n",
        "\n",
        "  if CUDA:\n",
        "      x_offset = x_offset.cuda()\n",
        "      y_offset = y_offset.cuda()\n",
        "\n",
        "  x_y_offset = torch.cat((x_offset, y_offset), 1).repeat(1,num_anchors).view(-1,2).unsqueeze(0)\n",
        "\n",
        "  prediction[:,:,:2] += x_y_offset\n",
        "  #log space transform height and the width\n",
        "  anchors = torch.FloatTensor(anchors)\n",
        "\n",
        "  if CUDA:\n",
        "      anchors = anchors.cuda()\n",
        "\n",
        "  anchors = anchors.repeat(grid_size*grid_size, 1).unsqueeze(0)\n",
        "  prediction[:,:,2:4] = torch.exp(prediction[:,:,2:4])*anchors\n",
        "  \n",
        "  prediction[:,:,5: 5 + num_classes] = torch.sigmoid((prediction[:,:, 5 : 5 + num_classes]))\n",
        "  \n",
        "  prediction[:,:,:4] *= stride\n",
        "  return prediction\n",
        "\n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzrnerfkjx-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfyVfmwVjx38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2YJV9fWjxwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfg8RUHojxa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbwY-sHivnVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Darknet(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Darknet, self).__init__()\n",
        "      self.blocks = parse_cfg()\n",
        "      self.net_info, self.module_list = create_modules(self.blocks)\n",
        "    def forward(self,x,CUDA):\n",
        "      modules = self.blocks[1:]  #as the first module is network information and has no role in the forward pass\n",
        "      outputs = {}               #as for the route and shortcut layers we would need the output feature maps of previous layers, hence we cache \n",
        "                                  #all of them in the dictionary 'outputs'\n",
        "      write = 0     #This is explained a bit later\n",
        "      for i, module in enumerate(modules): #iterating over the modules       \n",
        "        module_type = (module[\"type\"])\n",
        "        if module_type == \"convolutional\" or module_type == \"upsample\": #if the 'type' is [convolutional] or [upsample]\n",
        "          x = self.module_list[i](x)    #here 'x' is the input to darknet which will come in forthcoming snippets\n",
        "        elif module_type == \"route\":     #if module type is root\n",
        "          layers = modules[i][\"layers\"]  #access the \"layers\" of the i'th module\n",
        "          layers = [int(a) for a in layers] #converting layers to 'int'\n",
        "\n",
        "          if (layers[0]) > 0:               #equivalnet to start > 0 that comes in create_module function\n",
        "            layers[0] = layers[0] - i\n",
        "\n",
        "          if len(layers) == 1:\n",
        "            x = outputs[i + (layers[0])]   # if only one value in layers, then the output 'x' will be the feature map of i+layers[0] 'th layer\n",
        "\n",
        "\n",
        "          else:\n",
        "            if (layers[1]) > 0:            #equivalent explaination to end>0 that comes in create_module function\n",
        "              layers[1] = layers[1] - i\n",
        "\n",
        "            map1 = outputs[i + layers[0]]  #creating the 2 feature map variables for concatenation. \n",
        "            map2 = outputs[i + layers[1]]                    \n",
        "\n",
        "            x = torch.cat((map1, map2), 1) #concat along the depth dimension \n",
        "\n",
        "        elif  module_type == \"shortcut\":\n",
        "            from_ = int(module[\"from\"])\n",
        "            x = outputs[i-1] + outputs[i+from_] #as shortcut layer does addition of the previous and the layer before the skip connection node.\n",
        "            \n",
        "        elif module_type == 'yolo':        # if type = [yolo]\n",
        "          anchors = self.module_list[i][0].anchors  #assigns the value of 'anchors' from conv2d ?? in i'th module || DOUBT:NO ANCHORS in module_list\n",
        "          #Get the input dimensions\n",
        "          inp_dim = int (self.net_info[\"height\"])  #assigns the value of 'height' from [net] \n",
        "\n",
        "          #Get the number of classes\n",
        "          num_classes = int (module[\"classes\"])   #assigns the value of classes from module || DOUBT:NO CLASSES IN MODULE\n",
        "\n",
        "          #Transform \n",
        "          x = x.data   #data which goes inside the yolo layer\n",
        "          x = predict_transform(x, inp_dim, anchors, num_classes, CUDA)\n",
        "          if not write:              #if no collector has been intialised. \n",
        "              detections = x\n",
        "              write = 1\n",
        "\n",
        "          else:       \n",
        "              detections = torch.cat((detections, x), 1)\n",
        "\n",
        "        outputs[i] = x\n",
        "      return detections\n",
        "      \n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9HN0titg7tm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "2069fb00-2d06-46c6-b06e-1088e6343dc0"
      },
      "source": [
        "!wget https://github.com/ayooshkathuria/pytorch-yolo-v3/raw/master/dog-cycle-car.png"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-15 13:45:36--  https://github.com/ayooshkathuria/pytorch-yolo-v3/raw/master/dog-cycle-car.png\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ayooshkathuria/pytorch-yolo-v3/master/dog-cycle-car.png [following]\n",
            "--2019-07-15 13:45:37--  https://raw.githubusercontent.com/ayooshkathuria/pytorch-yolo-v3/master/dog-cycle-car.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347445 (339K) [image/png]\n",
            "Saving to: ‘dog-cycle-car.png’\n",
            "\n",
            "\rdog-cycle-car.png     0%[                    ]       0  --.-KB/s               \rdog-cycle-car.png   100%[===================>] 339.30K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-07-15 13:45:37 (6.64 MB/s) - ‘dog-cycle-car.png’ saved [347445/347445]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9wV4CsQwDlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_input(): \n",
        "  img = cv2.imread(\"/content/dog-cycle-car.png\")\n",
        "  img = cv2.resize(img, (608,608))          #Resize to the input dimension\n",
        "  img_ =  img[:,:,::-1].transpose((2,0,1))  # BGR -> RGB | H X W C -> C X H X W \n",
        "  img_ = img_[np.newaxis,:,:,:]/255.0       #Add a channel at 0 (for batch) | Normalise\n",
        "  img_ = torch.from_numpy(img_).float()     #Convert to float\n",
        "  img_ = Variable(img_)                     # Convert to Variable\n",
        "  return img_\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FGpoStNw3cw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a68faee3-7903-4b6b-aa25-60e5971a370f"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dog-cycle-car.png  yolov3.cfg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQS59pH5wL7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "8905b1f8-037c-4d60-fa2f-e87728d1cb69"
      },
      "source": [
        "model = Darknet()\n",
        "inp = get_test_input()\n",
        "pred = model(inp, torch.cuda.is_available())\n",
        "print (pred)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-36e002824101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDarknet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-ab342cbb70fe>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDarknet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCUDA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-161625cb3111>\u001b[0m in \u001b[0;36mparse_cfg\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/cfg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m                        \u001b[0;31m# store the lines in a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m               \u001b[0;31m# get read of the empty lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cfg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRdyxEHDwxFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}