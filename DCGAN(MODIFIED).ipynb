{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN(MODIFIED).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenzterBit/DL-QSTP-Codes/blob/master/DCGAN(MODIFIED).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZs5AUc86HYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn,optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms,datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smCq8VYA6KLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorboardx\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUMGlsaj7Jrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Wk3umy7sZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils import Logger"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m0SUgsX73Et",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform =transforms.Compose( [\n",
        "    transforms.Resize(64),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))\n",
        "])\n",
        "trainset = datasets.MNIST(root='./data',train = True, download = True,transform = transform)\n",
        "data_loader = torch.utils.data.DataLoader(trainset,batch_size = 128, shuffle = True )\n",
        "num_batches = len(data_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI8YoCvH991f",
        "colab_type": "code",
        "outputId": "24d9df52-8371-4ce5-d74a-0c6af6ffc7de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator,self).__init__()\n",
        "    in_features =1*28*28 \n",
        "    out = 1\n",
        "    \n",
        "    self.hidden0 = nn.Sequential(\n",
        "    nn.Conv2d(1,128,kernel_size=4, stride = 2 , padding = 1,bias=False),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    nn.BatchNorm2d(128)\n",
        "    )\n",
        "    \n",
        "    self.hidden1= nn.Sequential(\n",
        "    nn.Conv2d(128,256,4,2,1,bias=False),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    nn.BatchNorm2d(256)\n",
        "    )\n",
        "    \n",
        "    self.hidden2 = nn.Sequential(\n",
        "    nn.Conv2d(256,512,4,2,1,bias=False),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    nn.BatchNorm2d(512)\n",
        "    )\n",
        "    \n",
        "    self.hidden3 = nn.Sequential(\n",
        "    nn.Conv2d(512,1024,4,2,1,bias=False),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    nn.BatchNorm2d(1024)\n",
        "    )\n",
        "    \n",
        "    self.out = nn.Sequential(\n",
        "    nn.Conv2d(1024,1,4,1,0,bias=False),\n",
        "    nn.Sigmoid()\n",
        "    )\n",
        "    \n",
        "  def forward(self,x):\n",
        "    out = self.hidden0(x)\n",
        "    out = self.hidden1(out)\n",
        "    out = self.hidden2(out)\n",
        "    out = self.hidden3(out)\n",
        "    out = self.out(out)\n",
        "    return out\n",
        "\n",
        "discriminator = Discriminator()\n",
        "discriminator.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (hidden0): Sequential(\n",
              "    (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
              "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (hidden1): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
              "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (hidden2): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
              "    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (hidden3): Sequential(\n",
              "    (0): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
              "    (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (out): Sequential(\n",
              "    (0): Conv2d(1024, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jbVYwqiLNXN",
        "colab_type": "code",
        "outputId": "a2a52b05-19af-4b87-98c2-54e389a8c108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator,self).__init__()\n",
        "    \n",
        "    self.hidden0 = nn.Sequential(\n",
        "    nn.ConvTranspose2d(100,1024,kernel_size=4, stride = 1 , padding = 0,bias=False),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    nn.BatchNorm2d(1024),\n",
        "    nn.Dropout(0.3)\n",
        "    )\n",
        "    \n",
        "    self.hidden1= nn.Sequential(\n",
        "    nn.ConvTranspose2d(1024,512,4,2,1,bias=False),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.Dropout(0.3)\n",
        "    )\n",
        "    \n",
        "    self.hidden2 = nn.Sequential(\n",
        "    nn.ConvTranspose2d(512,256,4,2,1,bias=False),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.Dropout(0.3)\n",
        "    )\n",
        "    \n",
        "    self.hidden3 = nn.Sequential(\n",
        "    nn.ConvTranspose2d(256,128,4,2,1,bias=False),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.Dropout(0.3)\n",
        "    )\n",
        "    \n",
        "    self.out = nn.Sequential(\n",
        "    nn.ConvTranspose2d(128,1,4,2,1,bias=False),\n",
        "    nn.Tanh()\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    out = self.hidden0(x)\n",
        "    out = self.hidden1(out)\n",
        "    out = self.hidden2(out)\n",
        "    out = self.hidden3(out)\n",
        "    out = self.out(out)\n",
        "    return out\n",
        "\n",
        "generator = Generator()\n",
        "generator.cuda()\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (hidden0): Sequential(\n",
              "    (0): ConvTranspose2d(100, 1024, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
              "    (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.3)\n",
              "  )\n",
              "  (hidden1): Sequential(\n",
              "    (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
              "    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.3)\n",
              "  )\n",
              "  (hidden2): Sequential(\n",
              "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
              "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.3)\n",
              "  )\n",
              "  (hidden3): Sequential(\n",
              "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
              "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.3)\n",
              "  )\n",
              "  (out): Sequential(\n",
              "    (0): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4OyFQrtLvaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def make_ones_sp(size):\n",
        "  now = np.random.uniform(0.7,1.2)\n",
        "  #torch_now = torch.from_numpy(now)\n",
        "  ones = torch.zeros(size)\n",
        "  ones+= now\n",
        "  return Variable(ones.cuda())\n",
        "\n",
        "def make_zeros_sp(size):\n",
        "  now = np.random.uniform(0.0,0.3)\n",
        "  #torch_now = torch.from_numpy(now)\n",
        "  zeros = torch.zeros(size)\n",
        "  zeros+= now\n",
        "  return Variable(zeros.cuda())\n",
        "\n",
        "def make_ones(size):\n",
        "  data=Variable(torch.ones(size).cuda()) #do numpy random , and convert to pytorch .\n",
        "  return data\n",
        "\n",
        "def make_zeros(size):\n",
        "  data = Variable(torch.zeros(size).cuda())\n",
        "  return data\n",
        "\n",
        "def noise(size):\n",
        "  data = Variable(torch.randn(size,100).cuda())\n",
        "  return data\n",
        "def image_vector(image):\n",
        "  vec = image.view(image.shape[0],-1)\n",
        "  return vec\n",
        "def vector_image(vector):\n",
        "  image = vector.view(vector.shape[0],1,28,28)\n",
        "  return image\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxK5TwdnRdfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_optimiser = torch.optim.Adam(discriminator.parameters(),lr = 0.0002 , betas=(0.5, 0.999))\n",
        "g_optimiser = torch.optim.Adam(generator.parameters(), lr =0.0002,betas=(0.5, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgp1DmghR6ry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = nn.BCELoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zHHBDZVCtui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc2Norm():\n",
        "  total_norm = 0\n",
        "  total_norm2= 0\n",
        "  for i in discriminator.parameters():\n",
        "    \n",
        "    param_norm = i.grad.data.norm(2)\n",
        "    total_norm += param_norm.item() ** 2\n",
        "  total_norm1 = total_norm ** (1. / 2)\n",
        "  \n",
        "  for p in generator.parameters():\n",
        "    \n",
        "    param_norm2 = p.grad.data.norm(2)\n",
        "    total_norm2 += param_norm.item() ** 2\n",
        "  total_norm3 = total_norm2 ** (1. / 2)\n",
        "  \n",
        "  return total_norm1,total_norm3\n",
        " \n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsMz32MoR-xX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_discriminator(optimiser, real_data, fake_data):\n",
        "  N = real_data.size(0)\n",
        "  optimiser.zero_grad()\n",
        "  #real data\n",
        "  r_pred = discriminator(real_data).squeeze()\n",
        "  \n",
        "  r_err = loss(r_pred,make_ones_sp(N))\n",
        "  \n",
        "  r_err.backward()\n",
        "  #fake data\n",
        "  f_pred = discriminator(fake_data).squeeze() #D(G(z))\n",
        "  \n",
        "  f_err = loss(f_pred, make_zeros_sp(N))\n",
        "  \n",
        "  f_err.backward()\n",
        "  \n",
        "  optimiser.step()\n",
        "  \n",
        "  return r_err+f_err , r_pred, f_pred\n",
        "\n",
        "def train_generator(optimiser , fake_data):\n",
        "  N=fake_data.size(0)\n",
        "  optimiser.zero_grad()\n",
        "  \n",
        "  f_pred = discriminator(fake_data).squeeze()\n",
        "  f_err= loss(f_pred,make_ones_sp(N))\n",
        "  f_err.backward()\n",
        "  optimiser.step()\n",
        "  return f_err\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E79cpkijYfTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_test_samples = 16\n",
        "test_noise = noise(num_test_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABg9oXqfUy02",
        "colab_type": "code",
        "outputId": "0d1d56d3-1b8a-4864-8ff9-5b0274a4b66e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "logger = Logger(model_name = 'DCGAN' , data_name = 'MNIST')\n",
        "num_epoch = 30\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "  for n_batch, (real_batch,_) in enumerate(data_loader):\n",
        "    N = real_batch.size(0)\n",
        "    \n",
        "    #train discriminator\n",
        "    real_data = Variable(real_batch.cuda())\n",
        "    fake_data = generator(noise(N).view(-1,100,1,1)).detach()\n",
        "    \n",
        "    d_err,d_r_pred,d_f_pred = train_discriminator(d_optimiser,real_data,fake_data)\n",
        "    \n",
        "    #train generator\n",
        "    \n",
        "    fake_data = generator(noise(N).view(-1,100,1,1)) #G(z)\n",
        "    g_err = train_generator(g_optimiser,fake_data)\n",
        "    \n",
        "    # Log batch error\n",
        "    logger.log(d_err, g_err, epoch, n_batch, num_batches)\n",
        "    # Display Progress every few batches\n",
        "    if (n_batch) % 100 == 0: \n",
        "        test_images = generator(test_noise.view(-1,100,1,1))\n",
        "        test_images = test_images.data\n",
        "        logger.log_images(\n",
        "            test_images.cpu(), num_test_samples, \n",
        "            epoch, n_batch, num_batches\n",
        "        );\n",
        "        # Display status Logs\n",
        "        logger.display_status(\n",
        "            epoch, num_epoch, n_batch, num_batches,\n",
        "            d_err, g_err, d_r_pred, d_f_pred\n",
        "        )\n",
        "        \n",
        "        d_norm,g_norm = calc2Norm()\n",
        "        print(\"D-Norm \",d_norm , \" G-Norm \",g_norm)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-91cd4c40f44d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DCGAN'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdata_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'MNIST'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreal_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Logger' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFakjLAycecG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lG0uaSSceYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeXQVjj5YPrT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}